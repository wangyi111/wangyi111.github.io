---
permalink: /
title: "Welcome"
#excerpt: "About me"
author_profile: true
classes: wide
---

Welcome to my home page „ã°! I am a PhD candidate at [Technical University of Munich (TUM)](https://www.tum.de/) under the supervision of [Prof. Xiaoxiang Zhu](https://www.lrg.tum.de/sipeo/team/zhu/) and [Dr. Conrad M Albrecht](https://conrad-m-albrecht.github.io/). My doctoral research focuses on self-/weakly-supervised machine learning techniques and their applications in remote sensing and Earth observation, especially in multimodal scenarios.

I got my master's degree at [University of Stuttgart](https://www.uni-stuttgart.de/), and my bachelor's degree at [Wuhan University](https://www.whu.edu.cn/). I come from Huai'an, a historical and cultural city in Jiangsu, east coast of China. I enjoy challenges and adventures, currently addicted to exploring the Alps through hiking and snowboardingüèÇ.

<div style="background-color:#f9f9f9; border-left:4px solid #ccc; padding:10px 15px; margin:30px 0; font-size:90%; box-shadow: 1px 1px 3px rgba(0,0,0,0.05);">

<ul>
 <li><strong>[2025-06]</strong> Our paper "<em><a href="https://arxiv.org/abs/2503.11849">Towards a Unified Copernicus Foundation Model for Earth Vision</a></em>" has been accepted to ICCV 2025.</li>
 <li><strong>[2025-06]</strong> Our paper <em><a href="https://openaccess.thecvf.com/content/CVPR2025W/EarthVision/html/Waldmann_Panopticon_Advancing_Any-Sensor_Foundation_Models_for_Earth_Observation_CVPRW_2025_paper.html">Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation</a></em> received the Best Paper Award at CVPR 2025 Earth Vision Workshop.</li>
</ul>

</div>


## Selected Publications

<img style="float:left;width:30%;box-shadow: 3px 3px 3px gray;margin-right:20px;margin-top:10px;" src="/assets/images/publications/copernicusfm.png">

[Towards a Unified Copernicus Foundation Model for Earth Vision](https://arxiv.org/abs/2503.11849), ICCV 2025. [<img src="https://img.shields.io/badge/repo-gray">](https://github.com/zhu-xlab/Copernicus-FM) \
***Yi Wang**, Zhitong Xiong, Chenying Liu, Adam J. Stewart, Thomas Dujardin, Nikolaos Ioannis Bountos, Angelos Zavras, Franziska Gerken, Ioannis Papoutsis, Laura Leal-Taix√©, Xiao Xiang Zhu* \
`multimodal self-supervised learning`, `spectrum/language guided spectral/variable hypernetwork for any modality`, `Copernicus-Pretrain + Copernicus-FM + Copernicus-Bench` 

<div style="clear: both; margin-bottom:10px;"></div>


[Geolangbind: Unifying earth observation with agglomerative vision-language foundation models](https://arxiv.org/abs/2503.06312), Arxiv 2025. [<img src="https://img.shields.io/badge/repo-gray">](https://github.com/xiong-zhitong/GeoLB-SigLIP) \
*Zhitong Xiong, **Yi Wang**, Weikang Yu, Adam J Stewart, Jie Zhao, Nils Lehmann, Thomas Dujardin, Zhenghang Yuan, Pedram Ghamisi, Xiao Xiang Zhu* \
`vision-language model with any spectral sensor`, `SAR/MS/HS/RGB/langauge`

<div style="clear: both; margin-bottom:10px;"></div>


<img style="float:left;width:30%;box-shadow: 3px 3px 3px gray;margin-right:20px;margin-top:10px;" src="/assets/images/publications/softcon.png">

[Multi-Label Guided Soft Contrastive Learning for Efficient Earth Observation Pretraining](https://arxiv.org/abs/2405.20462), IEEE TGRS 2024. [<img src="https://img.shields.io/badge/repo-gray">](https://github.com/zhu-xlab/softcon) \
***Yi Wang**, Conrad M Albrecht, Xiao Xiang Zhu* \
`soft contrastive learning + continual pretraining`, `SAR/optical` 


<div style="clear: both; margin-bottom:10px;"></div>



<img style="float:left;width:30%;box-shadow: 3px 3px 3px gray;margin-right:20px;margin-top: 10px" src="/assets/images/publications/dofa.png">

[Neural Plasticity-Inspired Foundation Model for Observing the Earth Crossing Modalities](https://arxiv.org/abs/2403.15356), Arxiv 2024. [<img src="https://img.shields.io/badge/repo-gray">](https://github.com/zhu-xlab/dofa) \
*Zhitong Xiong, **Yi Wang**, Fahong Zhang, Adam J Stewart, Jo√´lle Hanna, Damian Borth, Ioannis Papoutsis, Bertrand Le Saux, Gustau Camps-Valls, Xiao Xiang Zhu* \
`wavelength dynamic hypernetwork enabling flexible spectral channels`, `SAR/MS/HS/RGB`

<div style="clear: both; margin-bottom:10px;"></div>

<img style="float:left;width:30%;box-shadow: 3px 3px 3px gray;margin-right:20px;margin-top: 10px" src="/assets/images/publications/decur_eccv.png">

[Decoupling common and unique representations for multimodal self-supervised learning](https://arxiv.org/abs/2309.05300), ECCV 2024 (oral). [<img src="https://img.shields.io/badge/repo-gray">](https://github.com/zhu-xlab/decur) \
***Yi Wang**, Conrad M Albrecht, Nassim Ait Ali Braham, Chenying Liu, Zhitong Xiong, Xiao Xiang Zhu* \
`modality decoupling for better multimodal representations`, `SAR-MS/RGB-DEM/RGB-Depth`

<div style="clear: both; margin-bottom:5px;"></div>


<img style="float:left;width:30%;box-shadow: 3px 3px 3px gray;margin-right:20px;margin-top:10px;" src="/assets/images/publications/fgmae-1.png">

[Feature Guided Masked Autoencoder for self-supervised learning in remote sensing](https://arxiv.org/abs/2310.18653), IEEE JSTARS 2023. [<img src="https://img.shields.io/badge/repo-gray">](https://github.com/zhu-xlab/FGMAE) \
***Yi Wang**, Hugo Hern√°ndez Hern√°ndez, Conrad M Albrecht, Xiao Xiang Zhu* \
`masked image modeling with feature guidance`, `EuroSAT-SAR dataset`, `SAR/optical`

<div style="clear: both;margin-bottom:10px;"></div>


<img style="float:left;width:30%;box-shadow: 3px 3px 3px gray;margin-right:20px; margin-top:10px;" src="/assets/images/publications/ssl4eo-s12.png">

[SSL4EO-S12: A large-scale multimodal, multitemporal dataset for self-supervised learning in Earth observation](https://arxiv.org/abs/2211.07044), IEEE GRSM 2023. [<img src="https://img.shields.io/badge/repo-gray">](https://github.com/zhu-xlab/SSL4EO-S12) \
***Yi Wang**, Nassim Ait Ali Braham, Zhitong Xiong, Chenying Liu, Conrad M Albrecht, Xiao Xiang Zhu* \
`pretraining dataset&benchmark + extended in-domain studies`, `SAR/optical`

<div style="clear: both;margin-bottom:5px;"></div>

<img style="float:left;width:30%;box-shadow: 3px 3px 3px gray;margin-right:20px;margin-top:10px;" src="/assets/images/publications/ssl4eo-review.png">

[Self-supervised learning in remote sensing: A review](https://arxiv.org/abs/2206.13188), IEEE GRSM 2022. \
***Yi Wang**, Conrad M Albrecht, Nassim Ait Ali Braham, Lichao Mou, Xiao Xiang Zhu* \
`survey of self-supervised learning + preliminary in-domain studies`

<div style="clear: both;margin-bottom:10px;"></div>






